\documentclass{article} % \documentclass{} is the first command in any LaTeX code.  It is used to define what kind of document you are creating such as an article or a book, and begins the document preamble

\usepackage{amsmath} % \usepackage is a command that allows you to add functionality to your LaTeX code
\usepackage{pythonhighlight}
\usepackage[]{tikz}
\usepackage{fancybox}
\usepackage{amssymb}
\usepackage{pgfplots}
\usepackage{xskak}   
\usepackage{matlab-prettifier}
\usepackage[makeroom]{cancel}

% The preamble ends with the command \begin{document}
\begin{document} % All begin commands must be paired with an end command somewhere
\begin{center}
    
    \newpage

    \section*{Metodo dei residui}

        \(Ax=b, \ A_{nxn}\)\\
        \(Ax^{(k)}-b =r^{(k)}\)\\
        \(\downarrow\)\\
        \(Ax^{\underset{\text{Soluzione esatta}}{*}}-b=0\)\\

    Il residuo è il vettore nullo \(\rightarrow \ x=x^* \) \\
    In ogni altro caso \(A\tilde{x} \neq b \rightarrow A\tilde{x} - b \neq 0\)\\
    Cioè \(\tilde{x} \neq x^*\)\\

    \textbf{Proprietà} Sia fissato \(\tau >0\)\\
    Se \(\frac{||r^{(k)}||}{||b||}\leq \tau\) allora \(\frac{||x^{(k)-x^*}||}{||x^*||}\leq K(A)\tau\)
    \(\frac{||x^{(k)-x^*}||}{||x^*||}\leq K(A) \underset{\text{Supposto}\le \tau}{\frac{||r^{(k)}||}{||b||}}\leq \tau \Rightarrow \frac{||x^{(k)-x^*}||}{||x^*||}\leq K(A)\tau\)
    \\
    \(||x^{(x)}-x^*|| \leq \epsilon ||x^{(k+1)}||\)

    \begin{lstlisting}%[mathescape=true]%

        for K=0,1,2, ... , Kmax
            r=Ax_0-b
            x=Gx_0+c
            if  \frac{||x-x_0||}{||x||} \lt \tau \and \frac{||r||}{||b||} <lt \tau 
                return x_0
            end
            x_0=0
        end
    \end{lstlisting}

        
    
    
    M è simile ad A, \(M^{-1} ~ G ~ O\)\\
    \(G=(I-M^{-1}A)\)\\
    Allora M ha una "struttura semplice": diagonale triangolare superiore oppure triangolare inferiore\\
    \(Mx=Mx-Ax+b\)\\
    \
    \(Mx^{k+1}=\underbrace{(M-A)x^{(k)}+b}_{\Sigma^{k} \in \mathbb{R}^n}\)\\
    \(Mx^{k+1}=\Sigma^{(k)}\)

    \newpage

    \subsection*{Metodi di decomposizione}
    Sono un sottoinsieme dei metodi iterativi


    \begin{align*}
        Ax=b\ A \in \mathcal{R}^{n\times n}\\
        A=M-N\\
        (M-N)x=b\\
        Mx-Nx=b\\
        Mx=Nx+b \rightarrow Mx^{(k+1)}=Nx^{(k)}+b\\
        \text{Fissiamo} x^{0} \in \mathcal{R}^n\\
        \text{Kappesimo passaggio:}\ Mx^{(k+1)}=Nx^{(k)}+b\\
        p=Nx^{(k)}+b\\
        Mx^{(k+1)}=p\ \text{Risolviamo il sistema lineare:}\ x^{(k+1)}
    \end{align*}

    Questi metodi iterativi, hanno senso se il loro costo si attesta a meno di \(\mathcal{O}(n^3)\)

    A=\(\begin{pmatrix}
        a_{11} & a_{12} & a_{13} & ... & a_{1n}\\
        a_{21} & a_{22} & a_{23} & ... & a_{2n}\\
        a_{31} & a_{32} & a_{33} & ... & a_{3n}\\
        ...\\
        a_{n1} & a_{n2} & a_{n3} & ... & a_{nn}
    \end{pmatrix}\)
    =

    D=\(\begin{pmatrix}
        a_{11} & 0 & 0 & ... & 0\\
        0 & a_{22} & 0 & ... & 0\\
        0 & 0 & a_{33} & ... & 0\\
        ...\\
        0 & 0 & 0 & ... & a_{nn}
    \end{pmatrix}\)
    -
    E=\(\begin{pmatrix}
        a_{11} & 0 & 0 & ... & 0\\
        a & a_{22} & 0 & ... & 0\\
        a & a & a_{33} & ... & 0\\
        ...\\
        a & a & a & ... & a_{nn}
    \end{pmatrix}\)
    - 
    F=\(\begin{pmatrix}
        a_{11} & a & a & ... & a\\
        0 & a_{22} & a & ... & a\\
        0 & 0 & a_{33} & ... & a\\
        ...\\
        0 & 0 & 0 & ... & a_{nn}
    \end{pmatrix}\)

    A=D-E-F

    \subsubsection*{Metodo di Jacobi:}
    \begin{align*}
        A=D-E-F\\
        A=M-N\\
        M=D \rightarrow N=M-A\\
        D-(D-E-F)=\\
        \cancel{D}-\cancel{D}+E+F=E+F\\
    \end{align*}
\newpage
    \textbf{Jacobi}\newline
    \begin{align*}
        M=D, \ N=E+F\\
        Ax=b\\
        Mx=Nx+b\\
        Dx^{(k+1)}=(E+F)x^{(k)}+b\\
    \end{align*}


    \begin{align*}
        d=diag(D)={(a_{11}, a_{22},...,a_{nn})}^t\\
        x={(k+1)}=[(E+F)x^{(k)}+b]/d
    \end{align*}

    \(\begin{pmatrix}
        x_{1}^{(k+1)}\\
        x_{2}^{(k+1)} \\
        ...\\
        x_{n}^{(k+1)} \\
    \end{pmatrix}\)=
    [
        \(\begin{pmatrix}
            0 & -a_{12} & -a_{13} & ... & -a_{1n}\\
            -a_{21} & 0 & -a_{23} & ... & -a_{2n}\\
            -a_{31} & -a_{32} & 0 & ... & -a_{3n}\\
            ...\\
            -a_{n1} & -a_{n2} & -a_{n3} & ... & 0
        \end{pmatrix}\)

        \(\begin{pmatrix}
            x_{1}^{(k+1)}\\
            x_{2}^{(k+1)} \\
            ...\\
            x_{n}^{(k+1)} \\
        \end{pmatrix}\)
        +
        \(\begin{pmatrix}
            b_{1}\\
            b_{2} \\
            ...\\
            b_{n} \\
        \end{pmatrix}\)
    ]
    ./
    \(\begin{pmatrix}
        a_{11}\\
        a_{22} \\
        ...\\
        a_{nn} \\
    \end{pmatrix}\)
    \newline

    \(
        x_1^{(k+1)}=[-(
        a_{12}x_2^{(k)} + a_{13}x_3^{(k)} + ... + a_{1n}x_n^{(k)})]
    \)
    Cioè 
    \newline
    \(
        x_i^{(k+1)}=[-
        \sum_{\underset{j\neq i}{j=1} }^{n}a_{ij}x_j^{(k)} + b_i]/a_{ii}
    \)
    \newline
    \(
        Dx^{k+1}=(E+F)x^(k)+b\ \text{Versione che diamo a matlab}
    \)
    

    \begin{lstlisting}
        function [x1, k]=manulle(A,b,tau,x0,Kmax)
        %Dalla versione nel file pagina 268 togliamo G e C
        for k=1:Kmax
            r=b-A*x0;
            xnext=my_diag_sol(D,Nx*x0+b)
            .checkcond
            x0=x1


    \end{lstlisting}
    %20 aprile 2023
    Gauss-Seidel
\begin{align*}
    M=\underbrace{D-E}_{\text{Triangolare inferiore}}\\
    N=M-A=D-E-(D-E-F)\\
    =\cancel{D}-\cancel{E}-\cancel{D}+\cancel{E}+F=F\\
\end{align*}

\begin{align*}
    Mx^{(k+1)}=Nx^{(k+1)}+b\\
    (D-E)x^{(k+1)}=Fx^{(k)}+b\\
    \text{Passo 0:}\ x^{(0)}\\
    \text{Calcolo:}\ p=Fx^{(0)}+b\\
    \text{Risolviamo:}\ (D-E)x^{(0)}=p\\
    \\
    \text{Passo 1:}\ p=Fx^{(1)}+b\\
    \text{Risolviamo:}\ (D-E)x^{(0)}=p\\
    \\
    \dots
    \\
    \text{Passo n:}\ p=Fx^{(n)}+b\\
    \text{Risolviamo:}\ (D-E)x^{(n)}=p\\
\end{align*}

Proprietà:
\begin{align*}
    |a_{ii}|>\sum_{j=1}^{n}|a_{ij}|\\
    i\ \ a_{i1}\ a_{i2}\ ...\ a_{ii-1}\ a_{ii}\ a_{ii+1}\ ...\ a_{in}
\end{align*}
    Teorema di convergenza di Jacobi
    \begin{align*}
        ||J||_{\infty}=max_{i \in \left\{ 1,...,n\right\}} \sum_{j=1}^{n} \frac{|a_{ij}|}{|a_{ii|}}\\
        \text{Fissato i}\ \sum_{j=1}^{n} \frac{|a_{ij}|}{|a_{ii|}}= \frac{|a_{i1}|}{|a_{ii|}}+\frac{|a_{i2}|}{|a_{ii|}}+
        ...+\frac{|a_{ii-1}|}{|a_{ii|}}+\frac{|a_{ii+1}|}{|a_{ii|}}+...+\frac{|a_{in}|}{|a_{ii|}}=\\
        \frac{|a_{i1}|+|a_{i2}|+...+|a_{ii-1}|+|a_{ii+1}|+...+|a_{in}|}{|a_{ii|}}=\\
        \frac{\sum_{j=1}^{n}|a_{ij}|}{|a_{ii}|}=\frac{1}{|a_{ii}|} \times \sum_{j=1}^{n}|a_{ij}|\\
        \text{Per i=1}\ \frac{1}{|a_{11}|}\sum_{j=1}^{n}|a_{1j}|=s1\\
        \text{Per i=2}\ \frac{1}{|a_{22}|}\sum_{j=1}^{n}|a_{2j}|=s2\\
        \dots\\
        \text{Per i=n}\ \frac{1}{|a_{nn}|}\sum_{j=1}^{n}|a_{nj}|=sn\\
    \end{align*}
    Quindi:
    \begin{align*}
        ||x^{(k+1)}-x^{(k)}||_2 < \tau\\
        ||x^{(k)}-x^{(*)}|| \leq\\
        ||G^k||_{\infty}||x_0||_2
    \end{align*}
    No alla altra dimostrazione

    %Inter-geometrica metti immagine o sbattitene
    


\end{center}
\end{document} % This is the end of the document
